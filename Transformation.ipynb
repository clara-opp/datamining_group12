{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ec49e8",
   "metadata": {},
   "source": [
    "# 3. Transformation\n",
    "We will  address splitting the data, but also the main goals of Transformation, reshaping the data to fir our algorithms. Specifically we should focus correct data types and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f3627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joes-data/DataMiningProject/datamining_group12\n"
     ]
    }
   ],
   "source": [
    "import sys, site, platform, pandas as pd\n",
    "import os\n",
    "from utils_io import load_step, save_step\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "print(os.getcwd())\n",
    "df = load_step(\"df_preprocessed\")\n",
    "df_no_zero = load_step(\"df_no_zero_preprocessed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431a121",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "We are splitting our Target and our Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2fe144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Target Attribute\n",
    "target = \"popularity\"\n",
    "\n",
    "# Spliting Target and Features used for prediction\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "X_no_zero = df_no_zero.drop(columns=[target])\n",
    "y_no_zero = df_no_zero[target]\n",
    "\n",
    "# Train/Test Split normal\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train/Test Split without zeros (no zeros = nz)\n",
    "X_train_nz, X_test_nz, y_train_nz, y_test_nz = train_test_split(X_no_zero, y_no_zero, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568e63c",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Some of our numerical values are way larger than others. We should solve this issue by scaling our data. As mentioned, we will use StandardScaler. It is important not to do this AFTER splitting our data so as to avoid data leakage. We choose to split the \"duration_ms\", \"tempo\" and \"loudness\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Choosing Numeric Columns we want to Scale\n",
    "cols_to_scale = ['duration_ms', 'tempo', 'loudness']\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_nz_scaled = X_train_nz.copy()\n",
    "X_test_nz_scaled = X_test_nz.copy()\n",
    "\n",
    "# Scale \n",
    "X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "X_train_nz_scaled[cols_to_scale] = scaler.fit_transform(X_train_nz[cols_to_scale])\n",
    "X_test_nz_scaled[cols_to_scale] = scaler.transform(X_test_nz[cols_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab71a2",
   "metadata": {},
   "source": [
    "## Save Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066884fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_train.csv\n",
      "Saved X_test.csv\n",
      "Saved y_train.csv\n",
      "Saved y_test.csv\n",
      "Saved X_train_nz.csv\n",
      "Saved X_test_nz.csv\n",
      "Saved y_train_nz.csv\n",
      "Saved y_test_nz.csv\n",
      "Saved X_train_scaled.csv\n",
      "Saved X_test_scaled.csv\n",
      "Saved X_train_nz_scaled.csv\n",
      "Saved X_test_nz_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "# normal (with zeros)\n",
    "save_step(X_train, \"X_train\")\n",
    "save_step(X_test, \"X_test\")\n",
    "save_step(y_train, \"y_train\")\n",
    "save_step(y_test, \"y_test\")\n",
    "\n",
    "# without zeros\n",
    "save_step(X_train_nz, \"X_train_nz\")\n",
    "save_step(X_test_nz, \"X_test_nz\")\n",
    "save_step(y_train_nz, \"y_train_nz\")\n",
    "save_step(y_test_nz, \"y_test_nz\")\n",
    "\n",
    "# scaled normal (with zeros)\n",
    "save_step(X_train_scaled, \"X_train_scaled\")\n",
    "save_step(X_test_scaled, \"X_test_scaled\")\n",
    "\n",
    "# scaled without zeros\n",
    "save_step(X_train_nz_scaled, \"X_train_nz_scaled\")\n",
    "save_step(X_test_nz_scaled, \"X_test_nz_scaled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
