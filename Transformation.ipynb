{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ec49e8",
   "metadata": {},
   "source": [
    "# 3. Transformation\n",
    "We will  address splitting the data, but also the main goals of Transformation, reshaping the data to fir our algorithms. Specifically we should focus correct data types and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f3627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/joes-data/DataMiningProject/datamining_group12\n"
     ]
    }
   ],
   "source": [
    "import sys, site, platform, pandas as pd\n",
    "import os\n",
    "from utils_io import load_step, save_step\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "print(os.getcwd())\n",
    "df = load_step(\"step2_preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438f2bf",
   "metadata": {},
   "source": [
    "### Boolean Values\n",
    "Since \"explicit\" is boolean, we need to convert it to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c807ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Explicit Attribute from boolean to int\n",
    "df[\"explicit\"] = df[\"explicit\"].astype(int)\n",
    "\n",
    "# # Verify that we have converted this correctly\n",
    "# print('Dataset Info without Irrelevant Features:')\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d43f82",
   "metadata": {},
   "source": [
    "### Object Attributes\n",
    "We are now ready to get rid of the \"track_id\" and \"track_name\" features. We can also drop the features which we converted using One-Hot Encoding such as \"key\" and \"time_signature\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c40083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing track_id, track_name and key, time_siganture\n",
    "df = df.drop(columns=['track_id', 'track_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0431a121",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "We are splitting our Target and our Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2fe144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Target Attribute\n",
    "target = \"popularity\"\n",
    "\n",
    "# Spliting Target and Features used for prediction\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568e63c",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Some of our numerical values are way larger than others. We should solve this issue by scaling our data. As mentioned, we will use StandardScaler. It is important not to do this AFTER splitting our data so as to avoid data leakage. We choose to split the \"duration_ms\", \"tempo\" and \"loudness\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c190fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Choosing Numeric Columns we want to Scale\n",
    "cols_to_scale = ['duration_ms', 'tempo', 'loudness']\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Scale \n",
    "X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab71a2",
   "metadata": {},
   "source": [
    "## Save Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "066884fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved step3_X_train.csv\n",
      "Saved step3_X_test.csv\n",
      "Saved step3_y_train.csv\n",
      "Saved step3_y_test.csv\n",
      "Saved step3_X_train_scaled.csv\n",
      "Saved step3_X_test_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "save_step(X_train, \"step3_X_train\")\n",
    "save_step(X_test, \"step3_X_test\")\n",
    "save_step(y_train, \"step3_y_train\")\n",
    "save_step(y_test, \"step3_y_test\")\n",
    "\n",
    "save_step(X_train_scaled, \"step3_X_train_scaled\")\n",
    "save_step(X_test_scaled, \"step3_X_test_scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c836a57",
   "metadata": {},
   "source": [
    "## Drop Values with Popularity Score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58b31a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7920     71\n",
      "82251    63\n",
      "68729    32\n",
      "75656    64\n",
      "24803    18\n",
      "         ..\n",
      "6265     40\n",
      "54886    27\n",
      "76820    27\n",
      "860      44\n",
      "15795    25\n",
      "Name: popularity, Length: 70612, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are merging the train and test data again \n",
    "zero_train = pd.concat([X_train, y_train], axis=1)\n",
    "zero_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# # Test if merging was complete\n",
    "# zero_train.head()\n",
    "# zero_test.head()\n",
    "\n",
    "# Dropping 0 popularity of zero_train and zero_test\n",
    "drop_index = zero_train[zero_train['popularity'] == 0].index\n",
    "zero_train = zero_train.drop(drop_index)\n",
    "\n",
    "drop_index = zero_test[zero_test['popularity'] == 0].index\n",
    "zero_test = zero_test.drop(drop_index)\n",
    "\n",
    "# Checking that 0s are removed\n",
    "zero_train[zero_train['popularity']==0]\n",
    "\n",
    "# Re-Splitting popularity feature:\n",
    "zero_y_train = zero_train[['popularity']] # Double [] to make it a dataframe\n",
    "zero_X_train = zero_train.drop(columns=['popularity'])\n",
    "\n",
    "zero_y_test = zero_test[['popularity']] # Double [] to make it a dataframe\n",
    "zero_X_test = zero_test.drop(columns=['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3cfdc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration_ms', 'explicit', 'danceability', 'energy', 'loudness', 'mode',\n",
      "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
      "       'valence', 'tempo', 'genre__Classical_Opera',\n",
      "       'genre__Country_Americana', 'genre__Electronic_Dance',\n",
      "       'genre__Folk_Acoustic_Singer-Songwriter', 'genre__Hip-Hop_Rap',\n",
      "       'genre__Jazz_Blues', 'genre__Latin', 'genre__Metal',\n",
      "       'genre__Mood_Functional_Other', 'genre__Pop', 'genre__R&B_Soul_Funk',\n",
      "       'genre__Reggae_Ska_Dub', 'genre__Rock', 'genre__Soundtrack_Showtunes',\n",
      "       'genre__World_International', 'amount_genres', 'key_0', 'key_1',\n",
      "       'key_2', 'key_3', 'key_4', 'key_5', 'key_6', 'key_7', 'key_8', 'key_9',\n",
      "       'key_10', 'key_11', 'time_signature_1', 'time_signature_3',\n",
      "       'time_signature_4', 'time_signature_5', 'length', 'word_count',\n",
      "       'sentiment_neutral', 'sentiment_positive', 'popularity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(zero_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde0020",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c70359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Choosing Numeric Columns we want to Scale\n",
    "cols_to_scale = ['duration_ms', 'tempo', 'loudness']\n",
    "\n",
    "zero_X_train_scaled = X_train.copy()\n",
    "zero_X_test_scaled = X_test.copy()\n",
    "\n",
    "# Scale \n",
    "zero_X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "zero_X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda52d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved zero_y_train.csv\n",
      "Saved zero_X_train_scaled.csv\n",
      "Saved zero_y_test.csv\n",
      "Saved zero_X_test_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "save_step(zero_y_train, \"zero_y_train\")\n",
    "save_step(zero_X_train_scaled, \"zero_X_train_scaled\")\n",
    "save_step(zero_y_test, \"zero_y_test\")\n",
    "save_step(zero_X_test_scaled, \"zero_X_test_scaled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
